spring.application.name=exec

date.format=yyyy-MM-dd HH:mm:ss
logging.level.org.springframework=INFO
logging.level.com.mkyong=INFO
logging.level.com.zaxxer=ERROR
logging.level.root=ERROR

spring.datasource.hikari.connectionTimeout=20000
spring.datasource.hikari.maximumPoolSize=5

# logging.pattern.console=%-5level %logger{36} - %msg%n

## MySQL
spring.datasource.url=jdbc:mysql://localhost:3306/mydb
spring.datasource.username=mkyong
spring.datasource.password=password

# hibernate_sequence' doesn't exist
# spring.jpa.hibernate.use-new-id-generator-mappings=false

# drop n create table again, good for testing, comment this in production
spring.jpa.hibernate.ddl-auto=create-drop

## Swagger in http://localhost:8080/v3/api-docs
##  link to http://localhost:8080/swagger-ui/index.html
pmu-exec.openapi.dev-url=http://localhost:8080
pmu-exec.openapi.prod-url=https://bezkoder-api.com

#springdoc.api-docs.enabled=false
#springdoc.swagger-ui.enabled=false
#
#springdoc.swagger-ui.path=/bezkoder-documentation
#springdoc.api-docs.path=/bezkoder-api-docs
#
#springdoc.packages-to-scan=com.bezkoder.spring.swagger.controller
#springdoc.swagger-ui.tryItOutEnabled=true
#springdoc.swagger-ui.operationsSorter=method
#springdoc.swagger-ui.tagsSorter=alpha
#springdoc.swagger-ui.filter=true

##########################
## Kafka PROPS          ##
##########################
## Kafka topic config
#Specifies the name of the Kafka topic
spring.kafka.topic.name = pmu-events
#Defines the number of partitions for the topic. Partitions allow you to distribute data across multiple brokers and consumers for parallel processing and increased throughput.
spring.kafka.topic.partition-count = 1
# (Same as spring.kafka.topic.replica-count) Specifies the replication factor for the topic.
spring.kafka.topic.replication-factor=3
#Sets the retention period for messages in the topic. Messages older than the retention period will be automatically deleted. ( equivalent to 7 days)
spring.kafka.topic.retention.ms = 604800000
# Defines the cleanup policy for the topic. The compact policy ensures that only the latest message for each key is retained in the topic, which is useful for maintaining the latest state of data.
spring.kafka.topic.cleanup.policy = compact
#This property is not a standard Spring Kafka configuration property for defining the number of partitions.
#Redundant: The number of partitions is already defined by spring.kafka.topic.partition-count
#spring.kafka.partition.number=2

spring.kafka.bootstrap-servers=localhost:9092

## Kafka producer config
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
spring.kafka.producer.properties.spring.json.value.default.type=com.pmu2.exec.domain.CourseRecord

spring.kafka.consumer.group-id=my-group
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.properties.spring.json.value.default.type=com.pmu2.exec.domain.CourseRecord
spring.kafka.consumer.level.concurrency=3
spring.kafka.listener.ack-mode=manual

# Retry and DLT Configuration
spring.kafka.retry.topic.configuration.dlt-handler-method=handleDltCourseRecord
spring.kafka.retry.topic.configuration.auto-create-topics=false
spring.kafka.retry.topic.configuration.topic-suffixing-strategy=SUFFIX_WITH_INDEX_VALUE
spring.kafka.retry.topic.configuration.retry-topic-suffix=-retrytopic
spring.kafka.retry.topic.configuration.dlt-topic-suffix=-dlttopic
spring.kafka.retry.topic.configuration.num-retries=3
spring.kafka.retry.topic.configuration.backoff.delay=1000
spring.kafka.retry.topic.configuration.backoff.multiplier=1.0
spring.kafka.retry.topic.configuration.backoff.max-delay=3000



